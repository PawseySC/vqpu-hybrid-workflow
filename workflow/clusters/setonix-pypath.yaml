generic:
  cluster_class: "dask_jobqueue.SLURMCluster"
  cluster_kwargs:
    name: generic

    # Dask worker options
    cores: 128                 # Total number of cores per job
    memory: "220GB"                # Total amount of memory per job
    processes: 1                # Number of Python processes per job

    # python: python3                # Python executable
    death_timeout: 30           # Number of seconds to wait if a worker can not find a scheduler
    local_directory: "$TMPDIR"       # Location of fast local storage like /scratch or $TMPDIR
    shared_temp_directory: null       # Shared directory currently used to dump temporary security objects for workers
    # worker_command: "distributed.cli.dask_worker" # Command to launch a worker
    # worker_extra_args: []       # Additional arguments to pass to `dask-worker`
    # interfaces : 
    # for compute nodes, one of 'lo', 'bond0', 'hsn0', 'hsn1', 'enp65s0',
    # for login ondes, 'lo', 'bond0', 'ens1f0np0', 'hsn0', 'ens10f0', 'ens10f1', 'ens5f0', 'ens5f1', 'ens1f1np1'
    interface: "hsn0" 

    # SLURM resource manager options
    shebang: "#!/usr/bin/bash"
    queue: "work"
    account: "pawsey0001"
    walltime: "1:00:00"
    # env-extra: null
    job_script_prologue: 
      - "module load cmake/3.27.7"
      - "module load python/3.11.6"
      - "source /software/projects/pawsey0001/pelahi/py-prefect2/bin/activate"
      - "export PREFECT_HOME=/scratch/pawsey0001/pelahi/prefect2"
      - "export PYTHONPATH=$PYTHONPATH:/software/projects/pawsey0001/pelahi/vqpu-hybrid-workflow/"
      - "export OMP_NUM_THREADS=1"
      - "export OMP_PLACES=cores"
      - "export OMP_MAX_ACTIVE_LEVELS=4"
      - "echo \"Node state:\""
      - "hostname"
      - "python --version; echo $PYTHONPATH"
      - "prefect version"
      - "env | grep SLURM_"
    job_cpu: 1
    job_mem: "1GB"
    job_extra: null
    # add anything extra #SBATCH additions
    job_extra_directives: 
      - "--ntasks=1"
      - '-e dask_logs/dask_generic_worker_%J.err'
      - '-o dask_logs/dask_generic_worker_%J.log'
    log_directory: dask_logs
    silence_logs: 'info'
    job_directives_skip: ['-e', '-o']    

  # now for number of slurm jobs
  adapt_kwargs:
      minimum_jobs: 1
      maximum_jobs: 128
      minimum_workers: 1
      maximum_workers: 256
      target_duration: "30s" # Amount of time we want a computation to take. This affects how aggressively we scale up.
      interval: "1s" # Milliseconds between checks
      wait_count: 1 # Number of consecutive times that a worker should be suggested for removal before we remove it.

circuit:
  cluster_class: "dask_jobqueue.SLURMCluster"
  cluster_kwargs:
    name: circuit

    # Dask worker options
    cores: 128                 # Total number of cores per job
    memory: "220GB"                # Total amount of memory per job
    processes: 1                # Number of Python processes per job

    # python: python3                # Python executable
    death_timeout: 30           # Number of seconds to wait if a worker can not find a scheduler
    local_directory: "$TMPDIR"       # Location of fast local storage like /scratch or $TMPDIR
    shared_temp_directory: null       # Shared directory currently used to dump temporary security objects for workers
    # worker_command: "distributed.cli.dask_worker" # Command to launch a worker
    # worker_extra_args: []       # Additional arguments to pass to `dask-worker`
    # interfaces : 
    # for compute nodes, one of 'lo', 'bond0', 'hsn0', 'hsn1', 'enp65s0',
    # for login ondes, 'lo', 'bond0', 'ens1f0np0', 'hsn0', 'ens10f0', 'ens10f1', 'ens5f0', 'ens5f1', 'ens1f1np1'
    interface: "hsn0" 

    # SLURM resource manager options
    shebang: "#!/usr/bin/bash"
    queue: "work"
    account: "pawsey0001"
    walltime: "1:00:00"
    # env-extra: null
    job_script_prologue: 
      - "module load cmake/3.27.7"
      - "module load python/3.11.6"
      - "source /software/projects/pawsey0001/pelahi/py-prefect2/bin/activate"
      - "export PREFECT_HOME=/scratch/pawsey0001/pelahi/prefect2"
      - "export PYTHONPATH=$PYTHONPATH:/software/projects/pawsey0001/pelahi/vqpu-hybrid-workflow/"
      - "export OMP_NUM_THREADS=1"
      - "export OMP_PLACES=cores"
      - "export OMP_MAX_ACTIVE_LEVELS=4"
      - "echo \"Node state:\""
      - "hostname"
      - "python --version; echo $PYTHONPATH"
      - "prefect version"
      - "env | grep SLURM_"
    job_cpu: 1
    job_mem: "1GB"
    job_extra: null
    # add anything extra #SBATCH additions
    job_extra_directives: 
      - "--ntasks=1"
      - '-e dask_logs/dask_circuit_worker_%J.err'
      - '-o dask_logs/dask_circuit_worker_%J.log'
    log_directory: dask_logs
    silence_logs: 'info'
    job_directives_skip: ['-e', '-o']    

  # now for number of slurm jobs
  adapt_kwargs:
      minimum_jobs: 1
      maximum_jobs: 128
      minimum_workers: 1
      maximum_workers: 256
      target_duration: "30s" # Amount of time we want a computation to take. This affects how aggressively we scale up.
      interval: "1s" # Milliseconds between checks
      wait_count: 1 # Number of consecutive times that a worker should be suggested for removal before we remove it.

vqpu:
  cluster_class: "dask_jobqueue.SLURMCluster"
  cluster_kwargs:
    name: vqpu

    # Dask worker options
    cores: 288                 # Total number of cores per job
    memory: "830GB"                # Total amount of memory per job
    processes: 1                # Number of Python processes per job

    # python: python3                # Python executable
    death_timeout: 30           # Number of seconds to wait if a worker can not find a scheduler
    local_directory: "$TMPDIR"       # Location of fast local storage like /scratch or $TMPDIR
    shared_temp_directory: null       # Shared directory currently used to dump temporary security objects for workers
    # worker_command: "distributed.cli.dask_worker" # Command to launch a worker
    # worker_extra_args: []       # Additional arguments to pass to `dask-worker`
    # interfaces : 
    # for compute nodes, one of 'lo', 'bond0', 'hsn0', 'hsn1', 'enp65s0',
    # for login ondes, 'lo', 'bond0', 'ens1f0np0', 'hsn0', 'ens10f0', 'ens10f1', 'ens5f0', 'ens5f1', 'ens1f1np1'
    interface: "hsn0" 

    # SLURM resource manager options
    shebang: "#!/usr/bin/bash"
    queue: "quantum"
    account: "pawsey0001"
    walltime: "24:00:00"
    env_extra: null
    job_script_prologue: 
      - "module load cmake/3.27.7"
      - "module load python/3.11.6"
      - "source /software/projects/pawsey0001/pelahi/py-prefect2/bin/activate"
      - "export PREFECT_HOME=/scratch/pawsey0001/pelahi/prefect2"
      - "export PYTHONPATH=$PYTHONPATH:/software/projects/pawsey0001/pelahi/vqpu-hybrid-workflow/"
      - "module use /software/projects/pawsey0001/pelahi/setonix/modules/arm64/custom/"
      - "module load vQPU-QB/1.7.0"
      - "source /software/projects/pawsey0001/pelahi//qb/qristal/1.7.0/bin/qbenv.sh"
      - "export PYTHONPATH=/software/projects/pawsey0001/pelahi//qb/qristal/1.7.0/sdk/lib64:/software/projects/pawsey0001/pelahi//qb/qristal/1.7.0/xacc:$PYTHONPATH:"
      - "export OMP_NUM_THREADS=32"
      - "export OMP_PLACES=cores"
      - "export OMP_MAX_ACTIVE_LEVELS=4"
      - "echo \"Node state:\""
      - "hostname"
      - "nvidia-smi"
      - "python --version; echo $PYTHONPATH"
      - "prefect version"
      - "env | grep SLURM_"
    job_cpu: 64
    job_mem: null
    job_extra: null
    job_extra_directives: 
      - "--gres=gpu:1"
      - "--nodes=1"
      - "--ntasks=1"
      - "--mem=200GB"
      - "--cpus-per-task=64"
      - '-e dask_logs/dask_vqpu_worker_%J.err'
      - '-o dask_logs/dask_vqpu_worker_%J.log'
    log_directory: dask_logs
    silence_logs: 'info'
    job_directives_skip: ['-e', '-o']    

  # now for number of slurm jobs
  adapt_kwargs:
      minimum_jobs: 1
      maximum_jobs: 4
      minimum_workers: 1
      maximum_workers: 4
      target_duration: "30s" # Amount of time we want a computation to take. This affects how aggressively we scale up.
      interval: "1s" # Milliseconds between checks
      wait_count: 1 # Number of consecutive times that a worker should be suggested for removal before we remove it.

gpu:
  cluster_class: "dask_jobqueue.SLURMCluster"
  cluster_kwargs:
    name: gpu

    # Dask worker options
    cores: 64                 # Total number of cores per job
    memory: "220GB"                # Total amount of memory per job
    processes: 1                # Number of Python processes per job

    # python: python3                # Python executable
    death_timeout: 30           # Number of seconds to wait if a worker can not find a scheduler
    local_directory: "$TMPDIR"       # Location of fast local storage like /scratch or $TMPDIR
    # shared_temp_directory: null       # Shared directory currently used to dump temporary security objects for workers
    # worker_command: "distributed.cli.dask_worker" # Command to launch a worker
    # worker_extra_args: []       # Additional arguments to pass to `dask-worker`
    # interfaces : 
    # for compute nodes, one of 'lo', 'bond0', 'hsn0', 'hsn1', 'enp65s0',
    # for login ondes, 'lo', 'bond0', 'ens1f0np0', 'hsn0', 'ens10f0', 'ens10f1', 'ens5f0', 'ens5f1', 'ens1f1np1'
    interface: "hsn0" 

    # SLURM resource manager options
    shebang: "#!/usr/bin/bash"
    queue: "gpu-dev"
    account: "pawsey0012-gpu"
    walltime: "1:00:00"
    env_extra: null
    job_script_prologue: 
      - "module load cmake/3.27.7"
      - "module load python/3.11.6"
      - "module load rocm/5.7.3"
      - "source /software/projects/pawsey0001/pelahi/py-prefect2/bin/activate"
      - "export PREFECT_HOME=/scratch/pawsey0001/pelahi/prefect2"
      - "export PYTHONPATH=$PYTHONPATH:/software/projects/pawsey0001/pelahi/vqpu-hybrid-workflow/"
      - "export OMP_NUM_THREADS=8"
      - "export OMP_PLACES=cores"
      - "export OMP_MAX_ACTIVE_LEVELS=4"
      - "echo \"Node state:\""
      - "hostname"
      - "rocm-smi"
      - "python --version; echo $PYTHONPATH"
      - "prefect version"
      - "env | grep SLURM_"
    job_cpu: 8
    #job_mem: null
    #job_extra: null
    job_extra_directives: 
      - "--gres=gpu:1"
      - "--nodes=1"
      - '-e dask_logs/dask_gpu_worker_%J.err'
      - '-o dask_logs/dask_gpu_worker_%J.log'
    log_directory: dask_logs
    silence_logs: 'info'
    job_directives_skip: ['-e', '-o', '-c', '--cpus-per-task', '--mem']    

    # Scheduler options
    # scheduler_options: {}
  # now for number of slurm jobs
  adapt_kwargs:
      minimum_jobs: 1
      maximum_jobs: 1
      minimum_workers: 1
      maximum_workers: 1
      target_duration: "3600s" # Amount of time we want a computation to take. This affects how aggressively we scale up.
      interval: "1s" # Milliseconds between checks
      wait_count: 1 # Number of consecutive times that a worker should be suggested for removal before we remove it.

cpu:
  cluster_class: "dask_jobqueue.SLURMCluster"
  cluster_kwargs:
    name: cpu

    # Dask worker options
    cores: 128                 # Total number of cores per job
    memory: "220GB"                # Total amount of memory per job
    processes: 4                # Number of Python processes per job

    python: python3                # Python executable
    death_timeout: 30           # Number of seconds to wait if a worker can not find a scheduler
    local_directory: "$TMPDIR"       # Location of fast local storage like /scratch or $TMPDIR
    shared_temp_directory: null       # Shared directory currently used to dump temporary security objects for workers
    worker_command: "distributed.cli.dask_worker" # Command to launch a worker
    worker_extra_args: []       # Additional arguments to pass to `dask-worker`
    # interfaces : 
    # for compute nodes, one of 'lo', 'bond0', 'hsn0', 'hsn1', 'enp65s0',
    # for login ondes, 'lo', 'bond0', 'ens1f0np0', 'hsn0', 'ens10f0', 'ens10f1', 'ens5f0', 'ens5f1', 'ens1f1np1'
    interface: "hsn0" 

    # SLURM resource manager options
    shebang: "#!/usr/bin/bash"
    queue: "work"
    account: "pawsey0001"
    walltime: "1:00:00"
    env_extra: null
    job_script_prologue: 
      - "module load cmake/3.27.7"
      - "module load python/3.11.6"
      - "source /software/projects/pawsey0001/pelahi/py-prefect2/bin/activate"
      - "export PREFECT_HOME=/scratch/pawsey0001/pelahi/prefect2"
      - "export PYTHONPATH=$PYTHONPATH:/software/projects/pawsey0001/pelahi/vqpu-hybrid-workflow/"
      - "export OMP_NUM_THREADS=8"
      - "export OMP_PLACES=cores"
      - "export OMP_MAX_ACTIVE_LEVELS=4"
      - "echo \"Node state:\""
      - "hostname"
      - "python --version; echo $PYTHONPATH"
      - "prefect version"
      - "env | grep SLURM_"
    job_cpu: 8
    job_mem: "32GB"
    job_extra: null

    job_extra_directives: 
      - "--nodes=1"
      - "--cpus-per-task=8"
      - '-e dask_logs/dask_cpu_worker_%J.err'
      - '-o dask_logs/dask_cpu_worker_%J.log'
    log_directory: dask_logs
    silence_logs: 'info'
    job_directives_skip: ['-e', '-o']    

  # now for number of slurm jobs
  adapt_kwargs:
      minimum_jobs: 1
      maximum_jobs: 16
      minimum_workers: 1
      maximum_workers: 32
      target_duration: "30s" # Amount of time we want a computation to take. This affects how aggressively we scale up.
      interval: "1s" # Milliseconds between checks
      wait_count: 1 # Number of consecutive times that a worker should be suggested for removal before we remove it.

generic-aws:
  cluster_class: "dask_jobqueue.SLURMCluster"
  cluster_kwargs:
    name: generic-aws

    # Dask worker options
    cores: 128                 # Total number of cores per job
    memory: "220GB"                # Total amount of memory per job
    processes: 1                # Number of Python processes per job

    # python: python3                # Python executable
    death_timeout: 30           # Number of seconds to wait if a worker can not find a scheduler
    local_directory: "$TMPDIR"       # Location of fast local storage like /scratch or $TMPDIR
    shared_temp_directory: null       # Shared directory currently used to dump temporary security objects for workers
    # worker_command: "distributed.cli.dask_worker" # Command to launch a worker
    # worker_extra_args: []       # Additional arguments to pass to `dask-worker`
    # interfaces : 
    # for compute nodes, one of 'lo', 'bond0', 'hsn0', 'hsn1', 'enp65s0',
    # for login ondes, 'lo', 'bond0', 'ens1f0np0', 'hsn0', 'ens10f0', 'ens10f1', 'ens5f0', 'ens5f1', 'ens1f1np1'
    interface: "hsn0" 

    # SLURM resource manager options
    shebang: "#!/usr/bin/bash"
    queue: "work"
    account: "pawsey0001"
    walltime: "1:00:00"
    # env-extra: null
    job_script_prologue: 
      - "module load cmake/3.27.7"
      - "module load python/3.11.6"
      - "source /software/projects/pawsey0001/pelahi/py-prefect2/bin/activate"
      - "export PREFECT_HOME=/scratch/pawsey0001/pelahi/prefect2"
      - "export PYTHONPATH=$PYTHONPATH:/software/projects/pawsey0001/pelahi/vqpu-hybrid-workflow/"
      - "export OMP_NUM_THREADS=1"
      - "export OMP_PLACES=cores"
      - "export OMP_MAX_ACTIVE_LEVELS=4"
      - "source /software/projects/pawsey0001/pelahi/aws_profile_env.sh"
      - "echo \"Node state:\""
      - "hostname"
      - "python --version; echo $PYTHONPATH"
      - "prefect version"
      - "env | grep SLURM_"
    job_cpu: 1
    job_mem: "8GB"
    job_extra: null
    # add anything extra #SBATCH additions
    job_extra_directives: 
      - "--ntasks=1"
      - '-e dask_logs/dask_generic_aws_worker_%J.err'
      - '-o dask_logs/dask_generic_aws_worker_%J.log'
    log_directory: dask_logs
    silence_logs: 'info'
    job_directives_skip: ['-e', '-o']    

  # now for number of slurm jobs
  adapt_kwargs:
      minimum_jobs: 1
      maximum_jobs: 128
      minimum_workers: 1
      maximum_workers: 256
      target_duration: "30s" # Amount of time we want a computation to take. This affects how aggressively we scale up.
      interval: "1s" # Milliseconds between checks
      wait_count: 1 # Number of consecutive times that a worker should be suggested for removal before we remove it.

generic-quera:
  cluster_class: "dask_jobqueue.SLURMCluster"
  cluster_kwargs:
    name: generic-quera

    # Dask worker options
    cores: 128                 # Total number of cores per job
    memory: "220GB"                # Total amount of memory per job
    processes: 1                # Number of Python processes per job

    # python: python3                # Python executable
    death_timeout: 30           # Number of seconds to wait if a worker can not find a scheduler
    local_directory: "$TMPDIR"       # Location of fast local storage like /scratch or $TMPDIR
    shared_temp_directory: null       # Shared directory currently used to dump temporary security objects for workers
    # worker_command: "distributed.cli.dask_worker" # Command to launch a worker
    # worker_extra_args: []       # Additional arguments to pass to `dask-worker`
    # interfaces : 
    # for compute nodes, one of 'lo', 'bond0', 'hsn0', 'hsn1', 'enp65s0',
    # for login ondes, 'lo', 'bond0', 'ens1f0np0', 'hsn0', 'ens10f0', 'ens10f1', 'ens5f0', 'ens5f1', 'ens1f1np1'
    interface: "hsn0" 

    # SLURM resource manager options
    shebang: "#!/usr/bin/bash"
    queue: "work"
    account: "pawsey0001"
    walltime: "1:00:00"
    # env-extra: null
    job_script_prologue: 
      - "module load cmake/3.27.7"
      - "module load python/3.11.6"
      - "source /software/projects/pawsey0001/pelahi/py-prefect2/bin/activate"
      - "export PREFECT_HOME=/scratch/pawsey0001/pelahi/prefect2"
      - "export PYTHONPATH=$PYTHONPATH:/software/projects/pawsey0001/pelahi/vqpu-hybrid-workflow/"
      - "source /software/projects/pawsey0001/pelahi/quera_profile_env.sh"
      - "export OMP_NUM_THREADS=1"
      - "export OMP_PLACES=cores"
      - "export OMP_MAX_ACTIVE_LEVELS=4"
      - "echo \"Node state:\""
      - "hostname"
      - "python --version; echo $PYTHONPATH"
      - "prefect version"
      - "env | grep SLURM_"
    job_cpu: 1
    job_mem: "8GB"
    job_extra: null
    # add anything extra #SBATCH additions
    job_extra_directives: 
      - "--ntasks=1"
      - '-e dask_logs/dask_generic_aws_worker_%J.err'
      - '-o dask_logs/dask_generic_aws_worker_%J.log'
    log_directory: dask_logs
    silence_logs: 'info'
    job_directives_skip: ['-e', '-o']    

  # now for number of slurm jobs
  adapt_kwargs:
      minimum_jobs: 1
      maximum_jobs: 128
      minimum_workers: 1
      maximum_workers: 256
      target_duration: "30s" # Amount of time we want a computation to take. This affects how aggressively we scale up.
      interval: "1s" # Milliseconds between checks
      wait_count: 1 # Number of consecutive times that a worker should be suggested for removal before we remove it.

distributed:
  worker:
    memory:
      target: False    # Avoid spilling to disk
      spill: False     # Avoid spilling to disk
